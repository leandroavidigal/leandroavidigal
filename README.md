### Ol√° eu sou o Leandro Vidigal üñêüèª
#### Data Engineer & AI | Analytics Engineer | AI Agents | ETL/ELT | Databricks, Snowflake, BigQuery | dbt, Airflow, Dataform | Python & SQL | GCP, AWS, Azure | Remote
[![Linkedin](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/leandrovidigal)

#### Forma√ß√£o
- Especializa√ß√£o - Agentes de AI com Redes Generativas | Institut d'Intelligence Artificielle Appliqu√©e ‚Äì I¬≤A¬≤  (2025)
-	Especializa√ß√£o - Data Science: Decis√µes Baseadas em Dados | - Massachusetts Institute of Technology - MIT (2025)
-	Cientista de Dados | Escola Brit√¢nica de Artes Criativas e Tecnologia - EBAC (2024)
-	Engenheiro de Dados | Faculdade XP Educa√ß√£o (2024)
-	Analista de Sistemas | Centro Universit√°rio Joaquim Nabuco de Recife (2022)
-	Engenheiro de Controle Automa√ß√£o | Universidade do Estado do Amazonas (2013)

#### Experi√™ncia Profissional
Sou Engenheiro de Dados com mais de 12 anos de experi√™ncia em ambientes corporativos complexos ‚Äî de bancos a startups, passando por √≥rg√£os p√∫blicos e multinacionais. Nos √∫ltimos 6 anos, atuei com foco em engenharia de dados e analytics engineering, projetando pipelines escal√°veis, confi√°veis e orientados √† performance.

Desenvolvo solu√ß√µes ELT/ETL robustas utilizando Python, SQL, dbt, Airflow, Dataform e Spark, em arquiteturas modernas baseadas em Databricks, Snowflake, BigQuery e Redshift. Tenho s√≥lida experi√™ncia em ambientes cloud (GCP, AWS e Azure), com √™nfase em governan√ßa, qualidade dos dados, particionamento eficiente e custo-benef√≠cio.

Especialidades:
‚Ä¢ Engenharia de Dados e Analytics Engineering
‚Ä¢ Orquestra√ß√£o e transforma√ß√£o com dbt, Airflow e Dataform
‚Ä¢ Databricks, Snowflake, BigQuery e Redshift
‚Ä¢ Pipelines em Python e SQL com foco em performance
‚Ä¢ Ambientes GCP, AWS e Azure
‚Ä¢ Monitoramento, testes automatizados, CI/CD e versionamento
‚Ä¢ Integra√ß√£o de dados estruturados e n√£o estruturados
‚Ä¢ Modelagem voltada a produtos de dados e KPIs confi√°veis

Atuo lado a lado com √°reas de neg√≥cio e engenharia, garantindo que os dados sirvam como base confi√°vel para decis√µes estrat√©gicas, produtos anal√≠ticos e pain√©is operacionais. Meu trabalho √© entregar dados bem modelados, documentados e prontos para uso ‚Äî com escalabilidade, seguran√ßa e rastreabilidade.


#### Evolu√ß√£o e Proje√ß√£o de Conhecimento
Minha trajet√≥ria de desenvolvimento e busca cont√≠nua por conhecimento ao longo dos anos.
![Grafico Github - Carreira](https://github.com/user-attachments/assets/6f0692a8-0029-4050-b71e-2f58eac08042)

#### Tecnologias que utilizo no meu dia a dia
<div style="display: inline_block"><br/>
  <img align="center" alt="html5" src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img align="center" alt="html5" src="https://img.shields.io/badge/MySQL-00000F?style=for-the-badge&logo=mysql&logoColor=white" /> 
  <img align="center" alt="html5" src="https://img.shields.io/badge/Amazon_AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white" /> 
  <img align="center" alt="html5" src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" /> 
</div>

#### Habilidades T√©cnicas

- **Engenharia de Dados**: Desenvolvimento e otimiza√ß√£o de pipelines de dados em ambientes Cloud (**AWS**, **GCP**); automa√ß√£o com CI/CD (Docker, Kubernetes, Jenkins).
- **Big Data**: Processamento e an√°lise de grandes volumes de dados utilizando Hadoop, Spark e Kafka.
- **Machine Learning**: Desenvolvimento de modelos preditivos com Python (Pandas, NumPy, Scikit-learn); implementa√ß√£o de pipelines de ML em produ√ß√£o.
- **An√°lise Estat√≠stica**: Aplica√ß√£o de estat√≠stica descritiva e inferencial; t√©cnicas avan√ßadas como regress√£o, teste de hip√≥teses e ANOVA.
- **An√°lise e Visualiza√ß√£o de Dados**: Cria√ß√£o de dashboards din√¢micos com Power BI e Python (Matplotlib, Seaborn); gera√ß√£o de insights para decis√µes baseadas em dados.
- **Bancos de Dados**: Modelagem e consultas avan√ßadas em bancos de dados SQL (PostgreSQL, MySQL, Redshift) e NoSQL.
- **Computa√ß√£o em Nuvem**: Experi√™ncia com AWS (Redshift, S3, Lambda) e GCP (BigQuery, Dataflow).
- **Orquestra√ß√£o e ETL**: Gest√£o de pipelines de dados com Airflow, DBT e ferramentas de automa√ß√£o.
- **Metodologias √Ågeis**: Uso de Scrum para gest√£o de projetos e equipes.

#### Contato
Estou sempre aberto a novas oportunidades e colabora√ß√µes na √°rea de Ci√™ncia de Dados. Se voc√™ est√° interessado em meu trabalho ou deseja discutir projetos potenciais, sinta-se √† vontade para entrar em contato.

______________________________________________________________________________________________________________________________________________________________________

### EN
### Hi, I'm Leandro Vidigal üñêüèª

#### Data Engineer & AI | Analytics Engineer | AI Agents | ETL/ELT | Databricks, Snowflake, BigQuery | dbt, Airflow, Dataform | Python & SQL | GCP, AWS, Azure | Remote
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/leandrovidigal)


#### Education
- Specialization ‚Äì AI Agents with Generative Networks | Institut d'Intelligence Artificielle Appliqu√©e ‚Äì I¬≤A¬≤ (2025)
-	Specialization in Data Science and Big Data: Data-Driven Decision Making - MIT (2025)
-	Data Scientist (2024)
-	Data Engineer (2024)
-	 Systems Analyst (2022)
-	Control and Automation Engineer (2013)

#### Professional Experience
I am a Data Engineer with more than 12 years of experience in complex corporate environments‚Äîranging from banks to startups, as well as public agencies and multinationals. Over the last 6 years, I have focused on data engineering and analytics engineering, designing scalable, reliable, and performance-oriented pipelines.

I develop robust ELT/ETL solutions using Python, SQL, dbt, Airflow, Dataform, and Spark, within modern architectures based on Databricks, Snowflake, BigQuery, and Redshift. I have solid experience in cloud environments (GCP, AWS, and Azure), with emphasis on governance, data quality, efficient partitioning, and cost-effectiveness.

![Grafico Github - Carreira Ingles](https://github.com/user-attachments/assets/8fc00276-7b78-4385-8328-e4a92d8cb286)

#### Technologies I Use Daily
<div style="display: inline_block"><br/>
  <img align="center" alt="Python" src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img align="center" alt="MySQL" src="https://img.shields.io/badge/MySQL-00000F?style=for-the-badge&logo=mysql&logoColor=white" /> 
  <img align="center" alt="Amazon AWS" src="https://img.shields.io/badge/Amazon_AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white" /> 
  <img align="center" alt="TensorFlow" src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" /> 
</div>

#### Technical Skills
- Data Engineering: Development and optimization of data pipelines in Cloud environments (AWS, GCP); automation with CI/CD (Docker, Kubernetes, Jenkins).
- Big Data: Processing and analysis of large data volumes using Hadoop, Spark, and Kafka.
- Machine Learning: Development of predictive models with Python (Pandas, NumPy, Scikit-learn); implementation of ML pipelines in production.
- Statistical Analysis: Application of descriptive and inferential statistics; advanced techniques like regression, hypothesis testing, and ANOVA.
- Data Analysis and Visualization: Creation of dynamic dashboards with Power BI and Python (Matplotlib, Seaborn); generating insights for data-driven decisions.
- Databases: Modeling and advanced queries in SQL (PostgreSQL, MySQL, Redshift) and NoSQL databases.
- Cloud Computing: Experience with AWS (Redshift, S3, Lambda) and GCP (BigQuery, Dataflow).
- Orchestration and ETL: Management of data pipelines with Airflow, DBT, and automation tools.
- Agile Methodologies: Use of Scrum for project and team management.

#### Contact
I am always open to new opportunities and collaborations in the field of Data Science. If you are interested in my work or would like to discuss potential projects, feel free to get in touch.

